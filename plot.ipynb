{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "from data.kernel import *\n",
    "from data.sampler import *\n",
    "from data.function import *\n",
    "from data.evaluation import * \n",
    "from policies.pbo import * \n",
    "from utils.plot import *\n",
    "from policies.transformer import * \n",
    "import os \n",
    "from data.candy_data_handler import * \n",
    "from data.sushi_data_handler import * \n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pbo_results(dataname, acq_function_type, dataset_id, num_seed=30, T=30):\n",
    "    root = f'results/evaluation/{dataname}/{acq_function_type}/{str(dataset_id)}'\n",
    "    simple_regret, cumulative_regret, inference_time, immediate_regret = list(), list(), list(), list()\n",
    "    for i in range(num_seed):\n",
    "        simple_regret.append(torch.load(os.path.join(root, f\"simple_regret_{i}.pt\"), map_location=\"cpu\")) # (H)\n",
    "        cumulative_regret.append(torch.load(os.path.join(root, f\"cumulative_regret_{i}.pt\"), map_location=\"cpu\"))\n",
    "        inference_time.append(torch.load(os.path.join(root, f\"cumulative_inference_time_{i}.pt\"), map_location=\"cpu\"))\n",
    "        immediate_regret.append(torch.load(os.path.join(root, f\"immediate_regret_{i}.pt\"), map_location=\"cpu\"))\n",
    "        \n",
    "    simple_regret = torch.stack(simple_regret) # (num_seeds, H)\n",
    "    cumulative_regret = torch.stack(cumulative_regret)\n",
    "    immediate_regret = torch.stack(immediate_regret)\n",
    "    inference_time = torch.stack(inference_time)\n",
    "    assert simple_regret.shape == (30, T+1), f\"{acq_function_type}, {simple_regret.shape}\"\n",
    "    assert cumulative_regret.shape == (30, T+1), f\"{acq_function_type}, {cumulative_regret.shape}\"\n",
    "    assert immediate_regret.shape == (30, T+1), f\"{acq_function_type}, {immediate_regret.shape}\"\n",
    "    assert inference_time.shape == (30, T), f\"{acq_function_type}, {inference_time.shape}\"\n",
    "    return simple_regret, cumulative_regret, immediate_regret, inference_time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results: dict, fig=None, i=0, row=1, col=3): \n",
    "    \"\"\"Plot simple regret, cumulative regret, and Cumulative inference time.\n",
    "    \n",
    "    Args: \n",
    "        results: dictionary of models' results. For a model m, results[m] is also a dictionary: \n",
    "            - simple_regret, (num_seed, num_dataset, H): simple regret along trajectories.\n",
    "            - cumulative_regret, (num_seed, num_dataset, H): cumulative regret along trajectories.\n",
    "            - inference_time, (num_seed, num_dataset, H): cumulative inference_time along trajectories.\n",
    "    \"\"\"\n",
    "    if fig is None: \n",
    "        fig = plt.figure(figsize=(16, 5))\n",
    "    model_names = list(results.keys())\n",
    "    ax = fig.add_subplot(row, col, i+1)\n",
    "    plot_metric_along_trajectory(metrics=[results[k][\"simple_regret\"].mean(dim=1) for k in model_names],\n",
    "                                 model_names=model_names, \n",
    "                                 ax=ax)\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax = fig.add_subplot(row, col, i+2)\n",
    "    plot_metric_along_trajectory(metrics=[results[k][\"cumulative_regret\"].mean(dim=1) for k in model_names],\n",
    "                                 model_names=model_names, \n",
    "                                 ax=ax)\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    ax = fig.add_subplot(row, col, i+3)\n",
    "    plot_metric_along_trajectory(metrics=[results[k][\"inference_time\"].mean(dim=1) for k in model_names],\n",
    "                                    model_names=model_names, \n",
    "                                    ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = \"sushi\"\n",
    "num_dataset=1\n",
    "results  = {}\n",
    "\n",
    "models = [\"rs\", \"qEUBO\", \"qTS\", \"qEI\", \"qNEI\", \"mpes\"]\n",
    "for acq_function_type in models: \n",
    "    results[acq_function_type] = dict()\n",
    "    results[acq_function_type][\"simple_regret\"]  = list()\n",
    "    results[acq_function_type][\"immediate_regret\"] = list()\n",
    "    results[acq_function_type][\"cumulative_regret\"] = list()\n",
    "    results[acq_function_type][\"inference_time\"] = list()\n",
    "    \n",
    "    for dataset_id in range(num_dataset): \n",
    "        simple_regret, cumulative_regret, immediate_regret, inference_time = read_pbo_results(dataname=dataname, \n",
    "                                                                                              acq_function_type=acq_function_type, \n",
    "                                                                                              dataset_id=dataset_id, \n",
    "                                                                                              T=100)\n",
    "        results[acq_function_type][\"simple_regret\"].append(simple_regret)\n",
    "        results[acq_function_type][\"cumulative_regret\"].append(cumulative_regret)\n",
    "        results[acq_function_type][\"inference_time\"].append(inference_time)\n",
    "        results[acq_function_type][\"immediate_regret\"].append(immediate_regret)\n",
    "    \n",
    "    results[acq_function_type][\"simple_regret\"]  = torch.stack(results[acq_function_type][\"simple_regret\"], dim=1) # (num_seed, num_dataset, H)\n",
    "    results[acq_function_type][\"cumulative_regret\"] = torch.stack(results[acq_function_type][\"cumulative_regret\"], dim=1)\n",
    "    results[acq_function_type][\"inference_time\"] = torch.stack(results[acq_function_type][\"inference_time\"], dim=1)\n",
    "    results[acq_function_type][\"immediate_regret\"] = torch.stack(results[acq_function_type][\"immediate_regret\"], dim=1)\n",
    "\n",
    "pabbo = \"PABBO_GP4D\"\n",
    "\n",
    "results[\"PABBO512\"] = dict()\n",
    "root = f'results/evaluation/{dataname}/PABBO/{pabbo}'\n",
    "results[\"PABBO512\"][\"simple_regret\"] =  torch.load(f\"{root}/SIMPLE_REGRET_S512_B1.pt\", map_location=\"cpu\")\n",
    "results[\"PABBO512\"][\"inference_time\"] = torch.load(f\"{root}/CUMULATIVE_TIME_S512_B1.pt\", map_location=\"cpu\")\n",
    "results[\"PABBO512\"][\"cumulative_regret\"] = torch.load(f\"{root}/CUMULATIVE_REGRET_S512_B1.pt\", map_location=\"cpu\")\n",
    "results[\"PABBO512\"][\"immediate_regret\"] = torch.load(f\"{root}/IMMEDIATE_REGRET_S512_B1.pt\", map_location=\"cpu\")\n",
    "\n",
    "\n",
    "plot_results(results)\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "plot_results(results, fig=fig)\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=len(results), bbox_to_anchor=(0.5, -0.1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
